{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b3478e",
   "metadata": {},
   "source": [
    "<h1 align=\\\"center\\\"><font color='green'><font size=\\\"6\\\">NLP with Python: Using NLTK and spaCy</font> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c38b6",
   "metadata": {},
   "source": [
    "<div style = \"background-color: #90EE90;\">.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7dd814",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through language. \n",
    "\n",
    "Python is a popular language for NLP due to its rich libraries, particularly NLTK and spaCy.\n",
    "\n",
    "### 1. NLTK (Natural Language Toolkit)\n",
    "NLTK is a powerful library for working with human language data. It provides easy-to-use tools for various NLP tasks, making it a great educational resource.\n",
    "\n",
    "#### Key Features:\n",
    "\n",
    " - **Tokenization**: Splitting text into words or sentences.\n",
    " - **Stemming and Lemmatization**: Reducing words to their base forms.\n",
    " - **Part-of-Speech Tagging**: Identifying the grammatical role of each word.\n",
    "\n",
    "**Use Case**\n",
    "\n",
    "NLTK is well-suited for educational purposes, helping students and researchers understand the fundamentals of NLP.\n",
    "\n",
    "Example: Basic NLTK Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f662303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample text\n",
    "text = \"Natural language processing is fascinating.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56bf925",
   "metadata": {},
   "source": [
    "## 2. spaCy\n",
    "spaCy is another popular NLP library designed for production-level tasks, focusing on efficiency and performance. It’s optimized for industrial use and real-time NLP applications.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    " - **Named Entity Recognition (NER)**: Identifying and categorizing entities (like people, organizations, dates) in text, making it easier to extract meaningful information.\n",
    " - **Fast Tokenization**: Quick splitting of text into tokens.\n",
    " - **Dependency Parsing**: Understanding the grammatical structure of sentences.\n",
    "\n",
    "### Advantages:\n",
    "\n",
    " - Well-organized, streamlined API with pre-built pipelines for speed and performance.\n",
    " - Uses optimized Python code to handle large datasets efficiently.\n",
    " \n",
    "\n",
    "Example: Basic spaCy Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9779a6",
   "metadata": {},
   "source": [
    "| Feature/Aspect         | **spaCy**                              | **NLTK**                             |\n",
    "|------------------------|---------------------------------------|--------------------------------------|\n",
    "| **Purpose**            | Designed for production-level tasks, focusing on efficiency and performance. | Primarily an educational tool for teaching and research in NLP. |\n",
    "| **Speed**              | Optimized for fast processing, handles large datasets efficiently. | Generally slower due to flexibility and manual processing steps. |\n",
    "| **Ease of Use**        | Streamlined API with pre-built pipelines for quick implementation. | More complex setup, often requiring manual assembly of the NLP pipeline. |\n",
    "| **Performance**        | High performance in real-time applications, ideal for industrial use. | Good for smaller projects and educational purposes, but not as performant in production. |\n",
    "| **Named Entity Recognition (NER)** | Provides robust and efficient NER capabilities out of the box. | NER is available but may require more setup and customization. |\n",
    "| **Tokenization**       | Fast and efficient tokenization, integrated into the pipeline. | Flexible tokenization options but can be slower. |\n",
    "| **Dependency Parsing** | Offers advanced dependency parsing with a focus on accuracy. | Also provides dependency parsing, but typically less optimized for speed. |\n",
    "| **Community and Support** | Growing community with good documentation, focused on production use cases. | Established community with extensive resources and tutorials, especially for beginners. |\n",
    "| **Customization**      | Less customizable out of the box but offers great performance. | Highly customizable, allowing for more research-oriented tasks. |\n",
    "| **Use Cases**          | Best for real-time applications like chatbots, web scraping, and production systems. | Best for educational purposes, prototyping, and smaller NLP tasks. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print named entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8dd97d",
   "metadata": {},
   "source": [
    "## Understanding BFS and DFS\n",
    "While BFS and DFS are not specifically NLP concepts, they are algorithms used in various computing tasks, including some NLP applications like parsing.\n",
    "\n",
    "#### Breadth-First Search (BFS)\n",
    "BFS explores all the neighbor nodes at the present depth before moving on to nodes at the next depth level. \n",
    "\n",
    "Example: Imagine you’re on a homepage and want to explore all its links:\n",
    "\n",
    " - Start at the homepage.\n",
    " - Visit all links on that page (e.g., About, Services, Contact).\n",
    " - For each of those links, visit all the links on those pages.\n",
    " - Continue this process level by level until you've explored to a certain depth.\n",
    "\n",
    "#### Depth-First Search (DFS)\n",
    "DFS explores as far as possible along each branch before backtracking.\n",
    "\n",
    "Example: Using the same homepage scenario, with DFS you’d do this:\n",
    "\n",
    " - Start at the homepage.\n",
    " - Click the first link (e.g., About) and explore all its links.\n",
    " - If there’s a link on the About page, follow that until there are no more links to explore.\n",
    " - Once you reach a dead end, go back to the previous page and explore the next link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbcbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
